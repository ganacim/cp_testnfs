{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_l = [ \"niagara\", \"nile\", \"kolyma\", \"euphrates\", ]\n",
    "site_l = [ \"local\", \"nfs\" ]\n",
    "bs_l = [ \"4k\", \"16k\", \"64k\", \"256k\", \"1m\", ]\n",
    "jobs_l = [ 1, 2, 4, 8, 16, ]\n",
    "fsize_l = [ \"1G\", \"5G\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(host, site, bs, jobs, fsize, figsize=(10, 5)):\n",
    "    modes = [ \"rand_write\", \"rand_read\", \"seq_write\", \"seq_read\", \"mixed_rw\" ]\n",
    "    plot_data = {}\n",
    "    host = [host] if isinstance(host, list) is False else host\n",
    "    site = [site] if isinstance(site, list) is False else site\n",
    "    bs = [bs] if isinstance(bs, list) is False else bs\n",
    "    jobs = [jobs] if isinstance(jobs, list) is False else jobs\n",
    "    file_size = [fsize] if isinstance(fsize, list) is False else fsize\n",
    "    for h, s, b, j, f in product(host, site, bs, jobs, file_size):\n",
    "        key = f\"{h}_{s}_bs{b}_jobs{j}_size{f}\"\n",
    "        plot_data[key] = {}\n",
    "        for m in modes:\n",
    "            with open(f\"results/{h}_{s}_bs{b}_jobs{j}_size{f}_{m}.txt\") as fd:\n",
    "                # print(fd)\n",
    "                data = json.load(fd)\n",
    "                if m.endswith(\"write\"):\n",
    "                    plot_data[key][m] = float(data[\"jobs\"][0][\"write\"][\"bw\"])/1024\n",
    "                elif m.endswith(\"read\"):\n",
    "                    plot_data[key][m] = float(data[\"jobs\"][0][\"read\"][\"bw\"])/1024\n",
    "                else:\n",
    "                    plot_data[key][\"mixed_read\"] = float(data[\"jobs\"][0][\"read\"][\"bw\"])/1024\n",
    "                    plot_data[key][\"mixed_write\"] = float(data[\"jobs\"][0][\"write\"][\"bw\"])/1024\n",
    "\n",
    "    # print(plot_data)\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=len(list(plot_data.keys())), layout=\"constrained\", figsize=figsize, sharey=True, squeeze=False)\n",
    "    ax = ax.flatten()\n",
    "    for k, (pname, pdata) in enumerate(plot_data.items()):\n",
    "        width = 0.25\n",
    "        x = np.arange(3)*0.6\n",
    "        seqrand = [\"Sequential\", \"Random\", \"Mixed\"]\n",
    "\n",
    "        name = {\n",
    "            \"Read\": [\"seq_read\", \"rand_read\", \"mixed_read\"],\n",
    "            \"Write\": [\"seq_write\", \"rand_write\", \"mixed_write\"],\n",
    "        }\n",
    "\n",
    "        for i, (key, value) in enumerate(name.items()):\n",
    "            rects = ax[k].bar(x + i*width, [pdata[v] for v in value], width=width, label=key)\n",
    "            ax[k].bar_label(rects, padding=3)\n",
    "\n",
    "        ax[k].set_title(pname)\n",
    "        ax[k].set_xticks(x + width/2, seqrand)\n",
    "        ax[k].legend(loc='best', ncols=3)\n",
    "        # ax[k].set_ylim(0)\n",
    "        # set horizontal grid\n",
    "        ax[k].yaxis.grid(True)\n",
    "    ax[0].set_ylabel('Bandwidth (MB/s)')\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# create_graph(\"niagara\", site=\"local\", bs=\"4k\", jobs=1, fsize=\"1G\")\n",
    "# create_graph(\"niagara\", site=\"local\", bs=bs_l, jobs=1, fsize=\"1G\", figsize=(20, 5))\n",
    "# create_graph(\"niagara\", site=\"local\", bs=bs_l, jobs=1, fsize=\"5G\", figsize=(20, 5))\n",
    "# create_plot(\"niagara\", site=\"local\", bs=\"4k\", jobs=jobs_l, fsize=\"5G\", figsize=(20, 5))\n",
    "# create_plot(\"niagara\", site=\"nfs\", bs=\"4k\", jobs=jobs_l, fsize=\"5G\", figsize=(20, 5))\n",
    "# create_plot(\"nile\", site=\"nfs\", bs=\"4k\", jobs=jobs_l, fsize=\"5G\", figsize=(20, 5))\n",
    "\n",
    "# create_graph(\"niagara\", \"nfs\", bs, jobs, fsize_l)\n",
    "# create_graph(\"niagara\", \"nfs\", bs_l, jobs, fsize, figsize=(20, 5))\n",
    "# create_graph(\"niagara\", \"nfs\", bs_l, jobs, \"5G\", figsize=(20, 5))\n",
    "# create_graph(\"kolyma\", site, bs, jobs, fsize)\n",
    "# create_graph(\"nile\", site, bs, jobs, fsize)\n",
    "# create_graph(\"euphrates\", site, bs, jobs, fsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um desktop típico do Centro Pi: niagara\n",
    "\n",
    "Usando o SSD (local), variando o tamanho dos blocos usados {4k, 16k, 256k, 1m}, com 1 processo (jobs), usando um de 5G dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(\"niagara\", site=\"local\", bs=bs_l, jobs=1, fsize=\"5G\", figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Leitura sequêncial melhora com o aumento do tamanho do bloco. (Qual é o limite?)\n",
    "* Escrita sequêncial varia muito pouco, porém tem um \"sweet spot\" com blocks de 16k. Talvez isso seja alguma característica do device, como o tamanho do block em disco.\n",
    "* Leitura e escrita aleatória diminuem muito a performance do SSD. Porém a escrita é mais rápida, talvez pelo buffer do SSD.\n",
    "* Leitura/Escrita misturadas tem o pior desempenho, mas representam melhor o caso de uso médio para um desktop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O mesmo teste usando arquivos de 1GB não mostra variação relevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(\"niagara\", site=\"local\", bs=bs_l, jobs=1, fsize=\"1G\", figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixando o tamanho do block em 4k e variando o número de jobs para simular \"usuários\" concorrentes.\n",
    "\n",
    "Os valores abaixo já estão agrupados, ié, os valores são a soma dos jobs individuais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(\"niagara\", site=\"local\", bs=\"4k\", jobs=jobs_l, fsize=\"5G\", figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A leitura sequencial cai muito. Talvez por deixar de ser sequencial, o que leva a operação para perto da leitura aleatória.\n",
    "* A escrita até 4 jobs melhora.\n",
    "* A leitura e escrita mista se mantem nos mesmos patamares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comparação: o mesmo teste acima com outros tamanhos de bloco. (Alguns testes estão com problema!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(\"niagara\", site=\"local\", bs=\"64k\", jobs=jobs_l, fsize=\"5G\", figsize=(20, 5))\n",
    "create_plot(\"niagara\", site=\"local\", bs=\"256k\", jobs=jobs_l, fsize=\"5G\", figsize=(20, 5))\n",
    "create_plot(\"niagara\", site=\"local\", bs=\"1m\", jobs=jobs_l, fsize=\"5G\", figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aumentar o block tem efeito positivo na leitura sequencial\n",
    "* Também melhorar a escrita/leitura mista.\n",
    "* Parece piorar para o caso aleatório."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetindo os teste para o niagara, porém usando o volume em NFS.\n",
    "\n",
    "Neste caso a rede foi deixada totalmente ociosa e nenhum outro processo acessava a euphrates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(\"niagara\", site=\"nfs\", bs=bs_l, jobs=1, fsize=\"5G\", figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variando o número de acesso concorrentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(\"niagara\", site=\"nfs\", bs=\"4k\", jobs=jobs_l, fsize=\"5G\", figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Leitura sequencia e aleatória são limitadas a 33MB/s para um job e sobem até 108MB/s, que é o limite da rede para a niagara, com mais jobs. Isto indica uma limitação do processo de NFS que tem throughput máxido de 33MB/s, aparentemente.\n",
    "* Leitura/Escrita misturada são muito baixas para blocos de 4kB, considerando que temos apenas 1 job. Melhor com mais jobs porém é possivel ver que o máximo de desempenho se antes (jobs < 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outros tamanhos de bloco:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(\"niagara\", site=\"nfs\", bs=\"64k\", jobs=jobs_l, fsize=\"5G\", figsize=(20, 5))\n",
    "create_plot(\"niagara\", site=\"nfs\", bs=\"256k\", jobs=jobs_l, fsize=\"5G\", figsize=(20, 5))\n",
    "create_plot(\"niagara\", site=\"nfs\", bs=\"1m\", jobs=jobs_l, fsize=\"5G\", figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aumentar o tamanho do bloco melhora o desempenho de leitura\n",
    "* Leitura aleatória ainda fica em ~33MB/s. Limitação de CPU para o NFS?\n",
    "* Estes gráfico sugerem que usar blocos de 64kB otimizaria o servidor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos repetir a análise para a nile. Nile tem interface de 10Gb/s (1125MB/s), portanto os testes devem passar de 112MB/s vistos acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(\"nile\", site=\"nfs\", bs=bs_l, jobs=1, fsize=\"5G\", figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(\"nile\", site=\"nfs\", bs=\"64k\", jobs=jobs_l, fsize=\"5G\", figsize=(20, 5))\n",
    "create_plot(\"nile\", site=\"nfs\", bs=\"256k\", jobs=jobs_l, fsize=\"5G\", figsize=(20, 5))\n",
    "create_plot(\"nile\", site=\"nfs\", bs=\"1m\", jobs=jobs_l, fsize=\"5G\", figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Neste caso dá para ver como a rede interfere nos números de leitura, chegando a > 1GB/s para bs de 1m e 4 jobs.\n",
    "* Uma dúvida é porque os casos de leitura/escrita misturadas são maiores que leitura e escrita aleatórias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comparação, estes são os dados da euphrates rodando os mesmos testes localmente (sem NFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(\"euphrates\", site=\"local\", bs=bs_l, jobs=1, fsize=\"5G\", figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(\"euphrates\", site=\"local\", bs=\"64k\", jobs=jobs_l, fsize=\"5G\", figsize=(20, 5))\n",
    "create_plot(\"euphrates\", site=\"local\", bs=\"256k\", jobs=jobs_l, fsize=\"5G\", figsize=(20, 5))\n",
    "create_plot(\"euphrates\", site=\"local\", bs=\"1m\", jobs=jobs_l, fsize=\"5G\", figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euphrates\n",
    "* Duas controladoras Apolo4510\n",
    "    *  /dev/sda é um RAID5 (?) de 260TB \n",
    "    * /dev/sdc é um RAID5 (?) de 180TB\n",
    "* /dev/md0 é um RAID 0 em software onde está /impa/home ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
